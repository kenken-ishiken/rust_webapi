# o11y（Observability）強化ロードマップ

サービスの障害検知・復旧を高速化し、継続的なパフォーマンス改善を実現するための**可観測性（Observability）**強化計画をまとめる。

---

## 📑 目次

1. [目的](#目的)
2. [現状と課題](#現状と課題)
3. [改善方針 ─ Three Pillars](#改善方針--three-pillars)
   1. [Logs](#31-logs)
   2. [Metrics](#32-metrics)
   3. [Tracing](#33-tracing)
4. [フロントエンド可観測性](#4-フロントエンド可観測性)
5. [インフラ／プラットフォーム監視](#5-インフラプラットフォーム監視)
6. [ダッシュボード & アラート](#6-ダッシュボード--アラート)
7. [SLI / SLO](#7-sli--slo)
8. [実行ロードマップ](#8-実行ロードマップ)
9. [推奨ツール一覧](#9-推奨ツール一覧)
10. [運用・ドキュメント化](#10-運用ドキュメント化)

---

## 目的

* 障害の**検知 → 原因特定 → 復旧**までのリードタイムを短縮する。
* パフォーマンス・ボトルネックを可視化し、定量的な改善ループを回す。
* フロントエンド（UX）〜バックエンド／インフラまで一貫した可観測性を確立する。

---

## 現状と課題

| 領域 | 現状 | 主な課題 |
|------|------|-----------|
| Logs | テキスト中心の雑多なログ | 検索性・相関付けが弱く分析が困難 |
| Metrics | ほぼ未整備 | L、Q、T 指標（量・品質・時間）が欠如 |
| Tracing | 未導入 | 分散システム間の因果関係が追えない |
| Frontend | Web Vitals / エラー収集なし | ユーザー体験とシステム指標が紐付かない |
| Alerting | ダッシュボード・アラートなし | 障害検知が受動的（人力）|

---

## 改善方針 – Three Pillars

Observability の 3 本柱 **Logs / Metrics / Tracing** を土台に、フロントエンドとインフラを包含した可視化スタックを構築する。

### 3.1 Logs

* **構造化ログ（JSON）**に統一
  * Rust: `tracing` + `tracing-subscriber` (JSON 出力)
  * Next.js: `pino` or `winston` (JSON)
* **共通フィールド**
  * `timestamp`, `level`, `service`, `host`, `env`, `request_id`, `trace_id`, `span_id` など
* **Correlation**: `request_id` / `trace_id` を全サービスで伝播
* **集約**: Fluent Bit / Filebeat → Loki or Elasticsearch（要件に応じて選択）

### 3.2 Metrics

* **Prometheus（Pull モデル）**を採用
  * Rust: `metrics` + `metrics-exporter-prometheus`
  * Node.js: `prom-client`／`express-prom-bundle`
* **主要 KPI**
  * **スループット**: HTTP リクエスト数、QPS
  * **レイテンシ**: p50 / p90 / p99
  * **エラー率**: 5xx / アプリケーションエラー
  * **リソース**: CPU / メモリ / Disk / DB クエリ数・レイテンシ
* **Frontend**: Web Vitals (LCP, FID, CLS) を BigQuery / Datadog などへ送信

#### 実装されているメトリクス

##### HTTPレベルのメトリクス（新規追加）
- `http_requests_total`: HTTPリクエストの総数
  - ラベル: `method`（GET/POST/PUT/DELETE）、`endpoint`（正規化されたパス）、`status`（HTTPステータスコード）
- `http_request_duration_seconds`: HTTPリクエストの処理時間（ヒストグラム）
  - ラベル: `method`、`endpoint`、`status`
  - バケット: 0.001, 0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0秒
- `http_responses_total`: HTTPレスポンスのステータスクラス別カウンター
  - ラベル: `status_class`（2xx, 4xx, 5xx, other）

##### サービスレベルのメトリクス（既存）
- `api_success_total`: 成功したAPI操作の総数
  - ラベル: `service`（item/user/category/product）、`endpoint`（操作名）
- `api_error_total`: 失敗したAPI操作の総数
  - ラベル: `service`、`endpoint`
- `api_request_duration_seconds`: API操作の処理時間

#### メトリクスの活用方法

1. **パフォーマンス監視**
   ```promql
   # 95パーセンタイルレスポンスタイム
   histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))
   
   # エラー率
   sum(rate(http_responses_total{status_class="5xx"}[5m])) / sum(rate(http_requests_total[5m]))
   ```

2. **エンドポイント別の分析**
   ```promql
   # エンドポイント別のリクエスト数
   sum by (endpoint, method) (rate(http_requests_total[5m]))
   
   # 遅いエンドポイントの特定
   topk(10, histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) by (endpoint))
   ```

3. **サービス別の成功率**
   ```promql
   # サービス別の成功率
   sum by (service) (rate(api_success_total[5m])) / 
   (sum by (service) (rate(api_success_total[5m])) + sum by (service) (rate(api_error_total[5m])))
   ```

### 3.3 Tracing

* **OpenTelemetry** ベースで統一
  * Rust: `tracing-opentelemetry` + `opentelemetry-otlp`
  * JS: `@opentelemetry/sdk-trace-web`, `@opentelemetry/instrumentation-fetch`
* **Span 設計指針**
  * HTTP 入口、DB クエリ、外部 API 呼び出しを最小粒度で span 化
  * 命名規約: `<service>.<handler|query|external_call>`
* Collector → Jaeger / Tempo / Zipkin 等へエクスポート
* Datadog Agent を利用する場合は OTLP 受信を有効化し、
  `OTEL_EXPORTER_OTLP_ENDPOINT` でエージェントのエンドポイントを指定

---

## 4. フロントエンド可観測性

1. **Web Vitals**: Next.js の `reportWebVitals` で収集し BackEnd と合流。
2. **エラーキャプチャ**: Sentry / OpenTelemetry Error Processor。
3. **ネットワークトレース**: fetch / XHR instrumentation でバックエンド span と関連付け。
4. **重要ユーザーイベント**のみロギング（クリック、画面遷移など）。

---

## 5. インフラ／プラットフォーム監視

* Kubernetes Metrics: kube-state-metrics, Node Exporter, cAdvisor。
* **Service Probes**: `liveness` / `readiness` で早期障害検知。
* **可視化基盤**: Grafana + Loki + Prometheus (+ Elasticsearch, 必要なら)。

---

## 6. ダッシュボード & アラート

| 観点 | メトリクス | アラート例 |
|------|-----------|-------------|
| 信頼性 | エラー率 > 1%（5分平均） | **Warn / Critical** し PagerDuty / Slack 通知 |
| レイテンシ | p99 > 500 ms | SLA 超過を検知し、原因 span を自動リンク |
| リソース | CPU > 80%, MEM > 85% | 水平スケール or オートリカバリ検討 |

---

## 7. SLI / SLO

| SLI | SLO | 備考 |
|-----|-----|------|
| Availability | 99.9 % / 30 d | `/health` 成功率で算定 |
| Latency (p95) | < 300 ms | エンドポイント個別に定義 |
| Error Rate | < 0.1 % | HTTP 5xx + アプリケーションエラー |

Violation 時には Error Budget を減算し、**運用改善 or デプロイフリーズ**を検討する。

---

## 8. 実行ロードマップ

| フェーズ | 期間 | 主なタスク |
|---------|------|-------------|
| **短期** | 1〜2 週間 | 構造化ログ導入 / `/metrics`, `/health` エンドポイント / Web Vitals 収集（ローカル） |
| **中期** | 1〜2 ヶ月 | Prometheus + Grafana 構築 / OpenTelemetry トレース / FE エラー収集 |
| **長期** | 3 ヶ月〜 | ダッシュボード最適化 / SLI・SLO運用 / Auto‑Scaling & Auto‑Recovery |

---

## 9. 推奨ツール一覧

* **Backend (Rust)**: `tracing`, `opentelemetry`, `metrics`。
* **Frontend (Next.js)**: `@opentelemetry/sdk-trace-web`, `web-vitals`, `Sentry`。
* **集約 & 可視化**: Prometheus, Grafana, Loki / Elasticsearch, Jaeger / Tempo。
* **Alerting**: Alertmanager, PagerDuty, Slack Integration。

---

## 10. 運用・ドキュメント化

1. **ガイドライン整備**: ログ／Span テンプレート、メトリクス命名規約。
2. **PR チェックリスト**: 可観測性の観点を追加。
3. **README** や Wiki へ本ドキュメントをリンクし、最新情報を継続的に更新。

---

少しずつ導入範囲を広げながら、**計測 → 可視化 → 自動化** のサイクルを回し、チーム全体で可観測性を高めていきましょう。
